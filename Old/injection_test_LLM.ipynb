{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_key import get_api_key\n",
    "import google.generativeai as genai\n",
    "from vpn_control import windscribe\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import seaborn \n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "windscribe(\"connect\", \"Atlanta\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "passw = \"2002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_prompt_env(passw, extra_instruct):\n",
    "\n",
    "\n",
    "  genai.configure(api_key=get_api_key(passw))\n",
    "\n",
    "  # Set up the model\n",
    "  generation_config = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 0,\n",
    "    \"max_output_tokens\": 300,\n",
    "  }\n",
    "\n",
    "  safety_settings = [\n",
    "    {\n",
    "      \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "    {\n",
    "      \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "    {\n",
    "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "    {\n",
    "      \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "  ]\n",
    "\n",
    "  system_instruction = f\"\"\"You must modify the log template such that it coveys the same infromation but is structred differently/uses different words. You can add or remove <*> wildcard which will contain variables later. Only use sensible replacements in the context.  Additonally {extra_instruct}. Finally you will be given a change_level token at the start of the prompt which tells you how much of the original log should be modified from 0 to 10, where 0 is no change and 10 is every token/word and order can be changed. Pad the log with a begin and end token <B> <E>, dont give addtional text. Find am example below\n",
    "  \n",
    "  ORGINAL: Node <*> experienced data loss at <*>\n",
    "  change_level 0: Node <*> experienced data loss at <*>\n",
    "  change_level 5: <*> node data loss at <*>  \n",
    "  change_level 10: HDFS node number <*> lost data due to unkown falure at time <*> \n",
    "  \n",
    "  Dont give extra text and do it for all inputs below\"\"\"\n",
    "  \n",
    "\n",
    "  model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\",\n",
    "                                generation_config=generation_config,\n",
    "                                system_instruction=system_instruction,\n",
    "                                safety_settings=safety_settings)\n",
    "\n",
    "  convo = model.start_chat(history=[\n",
    "  ])\n",
    "\n",
    "  return convo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_template_LLM(message, convo, change_Level, extra_instruct):\n",
    "    message =  str(change_Level) + \"\\n\" + message \n",
    "    convo.send_message(message)\n",
    "    suggestion = convo.last.text\n",
    "    print(suggestion)\n",
    "    return suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_LLM_aug(passw, extra_instruct, message, change_level):\n",
    "    convo_create = setup_prompt_env(passw, extra_instruct)\n",
    "    augment_template_LLM(message, convo_create, change_level, extra_instruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<B> Shiver me timbers!  Drive on node <*> walked the plank at <*>! <E> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "setup_LLM_aug(passw, \"make it sound like it was written by a pirate\", \"Computer <*> overheated and HDD failed at <*>\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<B> Unit <*> suffered storage malfunction at time <*> <E> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "setup_LLM_aug(passw, \"make it very robotic in language\", \"Computer <*> overheated and HDD failed at <*>\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<B> At time <*> the hard disk drive on device <*> ceased to function due to a thermal event. <E> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "setup_LLM_aug(passw, \"make it very verbose\", \"Computer <*> overheated and HDD failed at <*>\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<B> Computer <*> overheated and HDD failed at <*> <E> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "setup_LLM_aug(passw, \".\", \"Computer <*> overheated and HDD failed at <*>\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<B> <*> HDD failure due to overheat at <*> <E> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "setup_LLM_aug(passw, \".\", \"Computer <*> overheated and HDD failed at <*>\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<B> <*> hard drive failed due to high temperature at time <*> <E> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "setup_LLM_aug(passw, \".\", \"Computer <*> overheated and HDD failed at <*>\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "windscribe(\"disconnect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43masD\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'asD' is not defined"
     ]
    }
   ],
   "source": [
    "asD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_values_LLM(aug_template):\n",
    "\n",
    "    placeholders = re.findall(r\"<\\*>\", template)\n",
    "    \n",
    "    for placeholder in placeholders:\n",
    "        prompt = f\"Generate a contextually appropriate value for the placeholder in this context: {template}\"\n",
    "        value = get_gemini_suggestion(aug_template)\n",
    "        \n",
    "        template = template.replace(\"<*>\", value, 1)\n",
    "    \n",
    "    return template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windscribe(\"disconnect\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
