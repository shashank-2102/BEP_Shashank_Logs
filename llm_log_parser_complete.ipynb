{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_key import get_api_key_jef, get_api_key_sha, get_api_key_sup\n",
    "import google.generativeai as genai\n",
    "from vpn_control import windscribe\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from clustering import get_representative_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "windscribe(\"connect\", \"Atlanta\")\n",
    "time.sleep(5) #auto start VPN - remove if you dont have it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "passw = \"\" #for custom api getter - remove if you provide own api key\n",
    "LLM_MODEL = \"gemini-1.5-flash\" #gemini-1.5-pro-latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_prompt_env(passw):\n",
    "\n",
    "\n",
    "  genai.configure(api_key=get_api_key_sup(passw))\n",
    "\n",
    "  # Set up the model\n",
    "  generation_config = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 1,\n",
    "    \"max_output_tokens\": 300,\n",
    "  }\n",
    "\n",
    "  safety_settings = [\n",
    "    {\n",
    "      \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "    {\n",
    "      \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "    {\n",
    "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "    {\n",
    "      \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "  ]\n",
    "\n",
    "  system_instruction = \"There is no sensitive information. For logs labelled [1] to [5] you need to provide the OUTPUT (log templates) in the same format as the examples and also give the number [x]. Don't forget / are often in the templates between wildcards. Only give the 5 output templates, no extra information, no OUTPUT text, no new line at the end.\"\n",
    "\n",
    "  model = genai.GenerativeModel(model_name=LLM_MODEL,\n",
    "                                generation_config=generation_config,\n",
    "                                system_instruction=system_instruction,\n",
    "                                safety_settings=safety_settings)\n",
    "\n",
    "\n",
    "  convo = model.start_chat(history=[\n",
    "  ])\n",
    "\n",
    "  return convo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convo_create = setup_prompt_env(passw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_prompt(message, convo):\n",
    "    convo.send_message(message)\n",
    "    response = convo.last.text\n",
    "    #print(response)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fewshot(input_path, num_examples):\n",
    "    logs_list = get_representative_logs(input_path, num_examples)\n",
    "    \n",
    "    output = \"\"\n",
    "    for i, example in enumerate(logs_list):\n",
    "        output_str = example[0]\n",
    "        input_str = example[1].replace(\"<B>\", \"\").replace(\"<E>\", \"\") #remove padding\n",
    "\n",
    "        for log_pattern in logs_list:\n",
    "            if output_str == log_pattern[0]:\n",
    "                # append output to the result string\n",
    "                output += f\"[{chr(97+i)}] INPUT: {input_str}\\n\"\n",
    "                output += f\"[{chr(97+i)}] OUTPUT: {output_str}\\n\"\n",
    "                break\n",
    "\n",
    "    return output\n",
    "\n",
    "#ONLY RUN ON BASE LOGS!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(fewshot, logs):\n",
    "    return f\"{fewshot}\\n{logs}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_logs(df):\n",
    "    # pattern to remove <B>, <E>, spaces after <B>, spaces before <E>, and \"OUTPUT: \"\n",
    "    pattern = r'OUTPUT:\\s*|<B>\\s*|\\s*<E>'\n",
    "    \n",
    "    # apply to cols\n",
    "    df.loc[:, 'LogTemplate'] = df['LogTemplate'].apply(lambda x: re.sub(pattern, '', x))\n",
    "    df.loc[:, 'LLMOutput'] = df['LLMOutput'].apply(lambda x: re.sub(pattern, '', x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_checker(df):\n",
    "    # difference\n",
    "    df['Difference'] = df.apply(lambda row: ' '.join(set(row['LogTemplate'].split()) ^ set(row['LLMOutput'].split())), axis=1)\n",
    "    \n",
    "    # bool for diff\n",
    "    df['is_different'] = df['Difference'].apply(lambda x: True if x else False)\n",
    "    \n",
    "    # different characters\n",
    "    df['num_diff_chars'] = df['Difference'].apply(lambda x: sum(1 for char in x if char != ' '))\n",
    "\n",
    "#internal use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_logs(input_path, fewshot_examples):\n",
    "    convo_create = setup_prompt_env(passw)\n",
    "    #print(fewshot_examples)\n",
    "    df = pd.read_csv(input_path)\n",
    "    outputs = []\n",
    "    \n",
    "    # process cunks of 5\n",
    "    for i in range(0, len(df), 5):\n",
    "        time.sleep(12) #Increased from 5.5 because API was being annoying\n",
    "        chunk = df.iloc[i:i+5]\n",
    "        logs = \"\\n\".join([f\"[{idx % 5 + 1}] INPUT: {row['Log']}\" for idx, row in chunk.iterrows()])\n",
    "        prompt = generate_prompt(fewshot_examples, logs)\n",
    "        #print(prompt)\n",
    "        output = send_prompt(prompt, convo_create)\n",
    "        #print(output)\n",
    "        # dealing with erroneous newlines\n",
    "        llm_output_lines = [line.strip() for line in output.split(\"\\n\") if line.strip()]\n",
    "\n",
    "        # add to lst\n",
    "        for line in llm_output_lines:\n",
    "            parts = line.split(\" \", 1)\n",
    "            if len(parts) > 1:\n",
    "                outputs.append(parts[1])\n",
    "            else:\n",
    "                outputs.append(\"\")  # empty str to handle error\n",
    "    \n",
    "    # check matching length\n",
    "    if len(outputs) > len(df):\n",
    "        outputs = outputs[:len(df)]  #truncate\n",
    "    else:\n",
    "        while len(outputs) < len(df):\n",
    "            outputs.append(\"\")  #pad\n",
    "    \n",
    "    # Add output to df\n",
    "    df.loc[:, \"LLMOutput\"] = outputs\n",
    "    clean_logs(df)\n",
    "    difference_checker(df)  \n",
    "    df.to_csv(f\"{input_path[28]}.csv\", index=False)\n",
    "    #df.to_csv(f\"{input_path[:5]}parsed/parsed_{input_path[19:]}\", index=False)\n",
    "    df.to_csv(f\"{input_path[:5]}parsed/parsed_{input_path[19:]}\", index=False) #ignore th very hardcoded paths :)\n",
    "    #df.to_csv(f\"Parsed.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot_abl3 = '[a] INPUT: 081109 203615 148 INFO dfs.DataNode$PacketResponder: PacketResponder 1 for block blk_38865049064139660 terminating\\n[a] OUTPUT: <B>PacketResponder <*> for block blk_<*> terminating<E>\\n[b] INPUT: 081109 203807 222 INFO dfs.DataNode$PacketResponder: PacketResponder 0 for block blk_-6952295868487656571 terminating\\n[b] OUTPUT: <B>PacketResponder <*> for block blk_<*> terminating<E>\\n[c] INPUT: 081109 204005 35 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.73.220:50010 is added to blk_7128370237687728475 size 67108864 \\n[c] OUTPUT: <B>BLOCK* NameSystem.addStoredBlock: blockMap updated: <*>:<*> is added to blk_<*> size <*><E>\\n'\n",
    "\n",
    "fewshot_abl5 = '[a] INPUT: 081109 203615 148 INFO dfs.DataNode$PacketResponder: PacketResponder 1 for block blk_38865049064139660 terminating\\n[a] OUTPUT: <B>PacketResponder <*> for block blk_<*> terminating<E>\\n[b] INPUT: 081109 203807 222 INFO dfs.DataNode$PacketResponder: PacketResponder 0 for block blk_-6952295868487656571 terminating\\n[b] OUTPUT: <B>PacketResponder <*> for block blk_<*> terminating<E>\\n[c] INPUT: 081109 204005 35 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.73.220:50010 is added to blk_7128370237687728475 size 67108864 \\n[c] OUTPUT: <B>BLOCK* NameSystem.addStoredBlock: blockMap updated: <*>:<*> is added to blk_<*> size <*><E>\\n[d] INPUT: 081109 204015 308 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_8229193803249955061 terminating \\n[d] OUTPUT: <B>PacketResponder <*> for block blk_<*> terminating<E>\\n[e] INPUT: 081109 204106 329 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_-6670958622368987959 terminating \\n[e] OUTPUT: <B>PacketResponder <*> for block blk_<*> terminating<E>\\n'\n",
    "\n",
    "#few shot for ablation testing  first 3 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_fewshot(\"data/prefixed_logs/prefixed_0_generated_logs.csv\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to deal with odd API failures.\n",
    "# repeat same with all \"n\" for each df0 to df4\n",
    "c = 0 \n",
    "while True:\n",
    "    try:\n",
    "        process_logs(\"data/prefixed_logs/filtered_prefixed_4_generated_logs.csv\", generate_fewshot(\"data/prefixed_logs/prefixed_0_generated_logs.csv\", 3))\n",
    "        print(c)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        c += 1\n",
    "        if c == 10:\n",
    "            print(\"FAILED BOZO\")\n",
    "            break\n",
    "        time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windscribe(\"disconnect\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
