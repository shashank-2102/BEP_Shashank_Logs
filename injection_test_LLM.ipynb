{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_key import get_api_key\n",
    "import google.generativeai as genai\n",
    "from vpn_control import windscribe\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import seaborn \n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "windscribe(\"connect\", \"Atlanta\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passw = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_prompt_env(passw, extra_instruct):\n",
    "\n",
    "\n",
    "  genai.configure(api_key=get_api_key(passw))\n",
    "\n",
    "  # Set up the model\n",
    "  generation_config = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 0,\n",
    "    \"max_output_tokens\": 300,\n",
    "  }\n",
    "\n",
    "  safety_settings = [\n",
    "    {\n",
    "      \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "    {\n",
    "      \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "    {\n",
    "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "    {\n",
    "      \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "  ]\n",
    "\n",
    "  system_instruction = f\"\"\"You must modify the log template such that it coveys the same infromation but is structred differently/uses different words. You can add or remove <*> wildcard which will contain variables later. Only use sensible replacements in the context.  Additonally {extra_instruct}. Finally you will be given a change_level token at the start of the prom which tells you how much of the original log should be modified from 0 to 10, where 0 is no change and 10 is every token/word and order can be changed. Pas the log with a begin and end token <B> <E>, dont give addtional text. Find am example below\n",
    "  \n",
    "  ORGINAL: Node <*> experienced data loss at <*>\n",
    "  change_level 0: Node <*> experienced data loss at <*>\n",
    "  change_level 5: <*> node data loss at <*>  \n",
    "  change_level 10: HDFS node number <*> lost data due to unkown falure at time <*> \"\"\"\n",
    "\n",
    "  model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\",\n",
    "                                generation_config=generation_config,\n",
    "                                system_instruction=system_instruction,\n",
    "                                safety_settings=safety_settings)\n",
    "\n",
    "  convo = model.start_chat(history=[\n",
    "  ])\n",
    "\n",
    "  return convo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def augment_template_LLM(message, convo, change_Level, extra_instruct):\n",
    "    message =  str(change_Level) + \"\\n\" + message \n",
    "    convo.send_message(message)\n",
    "    suggestion = convo.last.text\n",
    "    print(suggestion)\n",
    "    return suggestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_LLM_aug(passw, extra_instruct, message, change_level):\n",
    "    convo_create = setup_prompt_env(passw, extra_instruct)\n",
    "    augment_template_LLM(message, convo_create, change_level, extra_instruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<B> Shiver me timbers! Thar be a <*> that be hotter than a kraken's breath, and the treasure chest be sunk at <*>! <E> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "setup_LLM_aug(passw, \"make it sound like it was written by a pirate\", \"Computer <*> overheated and HDD failed at <*>\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<B> Unit <*> experienced HDD malfunction following critical thermal event at <*> <E> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "setup_LLM_aug(passw, \"make it very robotic in language\", \"Computer <*> overheated and HDD failed at <*>\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<B> At the time instance of <*> , the hard disk drive of the computing device experienced a catastrophic failure due to exceeding thermal operating parameters. <E> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "setup_LLM_aug(passw, \"make it very verbose\", \"Computer <*> overheated and HDD failed at <*>\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<B> Computer <*> overheated and HDD failed at <*> <E> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "setup_LLM_aug(passw, \"use terms related to HDFS\", \"Computer <*> overheated and HDD failed at <*>\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<B> <*> HDD failure due to overheat in machine <*> <E> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "setup_LLM_aug(passw, \"use terms related to HDFS\", \"Computer <*> overheated and HDD failed at <*>\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<B> HDFS datanode <*> suffered a disk failure due to overheating at time <*> <E> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "setup_LLM_aug(passw, \"use terms related to HDFS\", \"Computer <*> overheated and HDD failed at <*>\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "windscribe(\"disconnect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43masD\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'asD' is not defined"
     ]
    }
   ],
   "source": [
    "asD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_values_LLM(aug_template):\n",
    "\n",
    "    placeholders = re.findall(r\"<\\*>\", template)\n",
    "    \n",
    "    for placeholder in placeholders:\n",
    "        prompt = f\"Generate a contextually appropriate value for the placeholder in this context: {template}\"\n",
    "        value = get_gemini_suggestion(aug_template)\n",
    "        \n",
    "        template = template.replace(\"<*>\", value, 1)\n",
    "    \n",
    "    return template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windscribe(\"disconnect\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
