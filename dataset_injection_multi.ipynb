{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_key import get_api_key_jef, get_api_key_sha, get_api_key_sup #custom API getter file\n",
    "import google.generativeai as genai\n",
    "from vpn_control import windscribe\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "windscribe(\"connect\", \"Atlanta\")\n",
    "time.sleep(5) #auto start VPN - remove if you dont have it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "passw = \"\" #for custom api getter - remove if you provide own api key\n",
    "LLM_MODEL = \"gemini-1.5-flash\" #gemini-1.5-pro-latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_prompt_env(passw, extra_instruct):\n",
    "\n",
    "\n",
    "  genai.configure(api_key=get_api_key_sup(passw))\n",
    "\n",
    "  # Set up the model\n",
    "  generation_config = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 0,\n",
    "    \"max_output_tokens\": 2500,\n",
    "  }\n",
    "\n",
    "  safety_settings = [\n",
    "    {\n",
    "      \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "    {\n",
    "      \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "    {\n",
    "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "    {\n",
    "      \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "      \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "    },\n",
    "  ]\n",
    "\n",
    "  system_instruction = f\"\"\"You must modify the log template such that it coveys the same infromation but is structred differently/uses different words. You can add or remove <*> wildcards which will contain variables later. Only use sensible replacements in the context. Additonally {extra_instruct}. You must provide a level 1, 2, 3 and 4 change of the original log, where 0 is no change and 4 is where every token/word and order can be changed. Pad each log with a begin and end token <B> <E> and give the change level [x] at the start. Find am example below of different change levels [x]\n",
    "  \n",
    "  INPUT: Node <*> experienced data loss at <*> due to network error\n",
    "\n",
    "  OUTPUT:\n",
    "  [0]: <B>Node <*> experienced data loss at <*> due to network error<E>\n",
    "  [1]: <B>Node <*> lost stored data at <*> due to network error<E>\n",
    "  [2]: <B>Node <*> experienced failure at <*> causing data loss<E>\n",
    "  [3]: <B>Due to network error <*> node lost all stored data at time <*><E>\n",
    "  [4]: <B>Severe node failure on <*> at <*> due to network disconnection causing data loss<E>\n",
    "  \n",
    " Dont give extra text.\"\"\"\n",
    "\n",
    "  model = genai.GenerativeModel(model_name=LLM_MODEL,\n",
    "                                generation_config=generation_config,\n",
    "                                system_instruction=system_instruction,\n",
    "                                safety_settings=safety_settings)\n",
    "\n",
    "  convo = model.start_chat(history=[\n",
    "  ])\n",
    "\n",
    "  return convo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_template_LLM(message, convo, extra_instruct):\n",
    "    message =  message \n",
    "    convo.send_message(message)\n",
    "    suggestion = convo.last.text\n",
    "    #print(suggestion)\n",
    "    return suggestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_LLM_aug(passw, extra_instruct, message):\n",
    "    convo_create = setup_prompt_env(passw, extra_instruct)\n",
    "    res = augment_template_LLM(message, convo_create, extra_instruct)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0]: <B>PacketResponder <*> for block blk_<*> terminating<E>\\n[1]: <B>PacketResponder <*> terminating for block blk_<*><E>\\n[2]: <B>PacketResponder <*> ending processing for block blk_<*><E>\\n[3]: <B>Block blk_<*> processing terminated by PacketResponder <*><E>\\n[4]: <B>PacketResponder <*> has stopped processing block blk_<*> due to an unknown event<E> \\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_LLM_aug(passw, \".\", \"<B>PacketResponder <*> for block blk_<*> terminating<E>\") #no exta instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data\\HDFS_2k.log_templates_aug.csv\") #local 2k dataset HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def augment_logs(df):\n",
    "    for index, row in df.iterrows():\n",
    "        time.sleep(10)\n",
    "        augmented_logs = setup_LLM_aug(passw, \".\", row['EventTemplate']).split('\\n')\n",
    "        for log in augmented_logs:\n",
    "            # check for expected delimiter\n",
    "            if ': ' in log:\n",
    "                col_index, augmented_log = log.split(': ', 1)\n",
    "                col_index = col_index.strip('[]')\n",
    "                df.at[index, col_index] = augmented_log\n",
    "    return df\n",
    "\n",
    "\n",
    "df = augment_logs(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/augmented_templates_flash.csv', index=False)\n",
    "#save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windscribe(\"disconnect\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
